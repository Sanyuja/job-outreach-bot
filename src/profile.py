# src/profile.py

BACKGROUND = """
[HEADLINE]
Senior Data Scientist with 7+ years of experience architecting and scaling production ML systems across domains including retail analytics, biological imaging, and operational decision pipelines. I specialize in enabling teams through automation, reproducibility, and end-to-end ownership of machine learning solutions.

[TARGET ROLES]
- Senior / Lead Data Scientist
- Applied Scientist / ML Scientist
- ML Engineer (applied + product-focused)
- Roles involving LLMs, GenAI, RAG systems, production ML, forecasting, risk/fraud analytics, and decision science

[THEMES IN MY WORK]
- I take ambiguous problems and convert them into reliable and reusable ML pipelines
- I build systems that keep working long after I’ve left
- I reduce manual toil through automation, workflow design, and tooling
- I love creating systems that empower scientists, analysts, and stakeholders

[RECENT EXPERIENCE]

University of Chicago — Lead Data Scientist (2025–Present)
- Architected reusable ML prediction platform (feature pipelines, MLflow registry, CI/CD, and inference), cutting model iteration time ~50%
- Productionized deep-learning microscopy + behavioral pipelines (CNN, U-Net, DeepLabCut, LSTMs/HMMs), scaling to 10K+ samples and reducing manual labeling ~80%
- Built a retrieval-augmented (RAG) research assistant using FAISS + OpenAI with guardrails and traceability for scientific literature review, reducing manual search effort ~60%
- Automated analytics via Snowflake + Power BI to deliver QC, reporting, and self-serve insights to scientific teams and clinicians
- Extended reproducibility + monitoring across projects (MLflow + Evidently), lowering reprocessing and failed runs ~30%
- Scaled pipelines to AWS (S3, Lambda, Batch, ECR) and doubled throughput of imaging/sequencing ETL
- Mentored junior researchers; standardized templates, coding practices, and onboarding — speeding ramp-up ~40%

NielsenIQ — Data Scientist (2021–2025)
- Designed a clustering + geospatial algorithm that correctly classified 105K+ retail locations, improving regional segmentation accuracy ~35%
- Increased automated price-change detection reliability ~50% using anomaly detection + econometrics
- Built seasonal forecasting baselines that improved accuracy ~25% and became trusted stakeholder tools
- Automated ETL + anomaly detection pipelines (PySpark + SQL) across 30K+ UPCs, reducing manual validation ~40%
- Developed AI-guided attribute extraction tool using LLM classification + pattern matching to eliminate manual tagging across thousands of UPCs
- Built Snowflake-backed dashboards that unlocked price, promo, and performance insights and expanded stakeholder adoption
- Mentored analysts + engineers; championed reproducibility, version control, and MLOps basics

WIN Home Inspection — Data Science Intern (2021)
- Built ETL from unstructured API to PostgreSQL
- Modeled operational efficiency drivers

UIC — Graduate Research Assistant (2018–2021)
- Managed and modeled large facility datasets
- Built data pipelines across cloud + SharePoint
- Applied GIS and utility mapping

Mohite & Shaw Pistons — Operations Analyst (2015–2017)
- Managed 80M+ SAS records to improve planning accuracy
- Designed supply-demand pipeline that reduced lead time ~28% and boosted productivity ~15%

[DOMAINS & PROBLEM SPACES]
- Production ML & MLOps
- Retail demand + pricing intelligence
- Biological imaging + video behavior analysis
- Operational analytics, ETL, forecasting, anomaly detection
- GenAI / RAG systems for research workflows
- AWS-scale model deployment and data pipelines

[STACK & TOOLBOX]
- ML + Stats: sklearn, PyTorch/TensorFlow (CNNs, LSTM/HMM), time series, clustering, anomaly detection, econometrics
- GenAI & RAG: embeddings, FAISS, LLM agents, traceability, prompt guardrails
- Data & Infra: Python, SQL, PySpark, MLflow, Evidently, Snowflake, AWS (S3/Lambda/Batch/ECR), Docker, Git, CI/CD
- BI & Visualization: Power BI, Plotly, Dash, dashboarding
- Scientific Data: microscopy, behavior tracking, omics QC, high-throughput analysis

[STRENGTHS & SUPERPOWERS]
- Turns vague problem statements into reliable, documented, production ML systems
- Loves automation and workflow architecture — building reusable templates, tools, and pipelines
- Can explain technical tradeoffs to scientists, execs, and engineering alike
- Develops standards + documentation that teams adopt and keep
- Deep ownership mindset — research → model → deploy → monitor → improve

[WORK STYLE & VALUES]
- Warm, direct communicator; avoids corporate-speak
- Bias toward action, iteration, and showing rather than telling
- Believes that good ML requires great data engineering and user empathy
- Cares about helping teams work faster with more confidence

[PERSONA FOR OUTREACH EMAILS]
- Confident but never arrogant
- Clear and pragmatic
- Focused on what I can contribute rather than “passion”
- Curious, grounded, and outcome-oriented
"""
